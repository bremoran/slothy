// 2
.macro barrett_32 a, Qbar, Q, tmp
    smmulr.w \tmp, \a, \Qbar
    mls.w \a, \tmp, \Q, \a
.endm

.syntax unified
.cpu cortex-m4

.align 2
.global __asm_asymmetric_mul_257_16_opt_m7
.type __asm_asymmetric_mul_257_16_opt_m7, %function
__asm_asymmetric_mul_257_16_opt_m7:
    push.w {r4-r11, lr}

    .equ width, 4

    add.w r12, r0, #256*width
    _asymmetric_mul_16_loop:
        _asymmetric_mul_16_loop_start:
                                         // Instructions:    14
                                         // Expected cycles: 12
                                         // Expected IPC:    1.17
                                         //
                                         // Wall time:     0.05s
                                         // User time:     0.05s
                                         //
                                         // ----- cycle (expected) ------>
                                         // 0                        25
                                         // |------------------------|----
        ldr.w r6, [r2, #width]           // *.............................
        ldr.w r4, [r1, #width]           // *.............................
        ldr.w r10, [r1], #2*width        // .*............................
        ldr.w r7, [r2], #2*width         // .*............................
        smuadx r6, r4, r6                // ..*...........................
        ldr.w r9, [r3, #width]           // ..*...........................
        smuadx r5, r10, r7               // ...*..........................
        ldr.w r11, [r3], #2*width        // ...*..........................
        smuad r7, r4, r9                 // ....*.........................
        str.w r5, [r0, #width]           // .....*........................
        smuad r10, r10, r11              // .....*........................
        str.w r10, [r0], #2*width        // .......*......................
        str.w r6, [r0, #width]           // .........*....................
        str.w r7, [r0], #2*width         // ...........*..................

                                          // ------ cycle (expected) ------>
                                          // 0                        25
                                          // |------------------------|-----
        // ldr.w r7, [r1, #width]         // *..............................
        // ldr.w r4, [r1], #2*width       // .*.............................
        // ldr.w r8, [r2, #width]         // *..............................
        // ldr.w r5, [r2], #2*width       // .*.............................
        // ldr.w r9, [r3, #width]         // ..*............................
        // ldr.w r6, [r3], #2*width       // ...*...........................
        // smuad r10, r4, r6              // .....*.........................
        // smuadx r11, r4, r5             // ...*...........................
        // str.w r11, [r0, #width]        // .....*.........................
        // str.w r10, [r0], #2*width      // .......*.......................
        // smuad r10, r7, r9              // ....*..........................
        // smuadx r11, r7, r8             // ..*............................
        // str.w r11, [r0, #width]        // .........*.....................
        // str.w r10, [r0], #2*width      // ...........*...................

        _asymmetric_mul_16_loop_end:


    cmp.w r0, r12
    bne.w _asymmetric_mul_16_loop

    pop.w {r4-r11, pc}